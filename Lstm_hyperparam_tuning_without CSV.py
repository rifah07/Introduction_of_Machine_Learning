# -*- coding: utf-8 -*-
"""LSTM_HyperParam_Tuning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11_wRnMUbfgE7sSwI8WayxyTuub2Rz-zT
"""

import numpy as np
import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# 1. Generate Sine Wave Dataset
def create_sine_wave_data(seq_length, n_samples):
    x = np.linspace(0, 50, n_samples)
    y = np.sin(x)
    data = []
    target = []
    for i in range(len(y) - seq_length):
        data.append(y[i:i + seq_length])    # Input: seq_length points
        target.append(y[i + seq_length])   # Output: Next point after the sequence
    return np.array(data), np.array(target)

seq_length = 10
n_samples = 500
X, y = create_sine_wave_data(seq_length, n_samples)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Convert to PyTorch tensors
X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)  # Add input_size=1
y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1)
X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1)
y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(-1)

# 2. Define LSTM Model
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.lstm(x)  # LSTM layer
        out = self.fc(out[:, -1, :])  # Fully connected layer
        return out

# 3. Train and Evaluate Model
def train_and_evaluate_model(hidden_size, num_layers, learning_rate, epochs=50):
    input_size = 1  # Single feature
    output_size = 1  # Predict one value
    model = LSTMModel(input_size, hidden_size, num_layers, output_size)

    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    # Train
    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()
        output = model(X_train)
        loss = criterion(output, y_train)
        loss.backward()
        optimizer.step()

    # Evaluate
    model.eval()
    with torch.no_grad():
        y_pred = model(X_test)
        test_loss = mean_squared_error(y_test.numpy(), y_pred.numpy())
    return test_loss, model

# 4. Hyperparameter Tuning (Grid Search)
hidden_sizes = [16, 32, 64]
num_layers_list = [1, 2]
learning_rates = [0.001, 0.01]
epochs = 50

best_loss = float('inf')
best_params = None
best_model = None

for hidden_size in hidden_sizes:
    for num_layers in num_layers_list:
        for learning_rate in learning_rates:
            print(f"Testing: hidden_size={hidden_size}, num_layers={num_layers}, learning_rate={learning_rate}")
            test_loss, model = train_and_evaluate_model(hidden_size, num_layers, learning_rate, epochs)
            print(f"Test Loss: {test_loss:.4f}")

            if test_loss < best_loss:
                best_loss = test_loss
                best_params = (hidden_size, num_layers, learning_rate)
                best_model = model

print("\nBest Parameters:")
print(f"Hidden Size: {best_params[0]}, Num Layers: {best_params[1]}, Learning Rate: {best_params[2]}")
print(f"Best Loss: {best_loss:.4f}")

# 5. Predict with Best Model
y_pred = best_model(X_test).detach().numpy()
y_test = y_test.numpy()

# 6. Visualize Results
plt.figure(figsize=(10, 6))
plt.plot(y_test, label="True Values", color='blue')
plt.plot(y_pred, label="Predictions", color='red', linestyle='--')
plt.legend()
plt.title("True Values vs. Predictions")
plt.xlabel("Sample Index")
plt.ylabel("Sine Wave Value")
plt.show()

"""Explanation in Simple Words

1. Dataset:
    * We use a sine wave as the dataset. The input sequences are seq_length time steps long, and the output is the next value in the sine wave.

2. Model:
    * The LSTM predicts the next value in the sequence.

3. Hyperparameters:
    * hidden_size: Number of neurons in the LSTM.
    * num_layers: Number of stacked LSTM layers.
    * learning_rate: Step size for optimizer updates.

4. Grid Search:
    * We try all combinations of the hyperparameters (hidden_size, num_layers, learning_rate).
    * For each combination, the model is trained and evaluated on the test set.
    * The combination with the lowest test loss is chosen as the best.

5. Evaluation:
    * The performance is measured using Mean Squared Error (MSE).

## The function returns two numpy arrays:
1. data: A 2D array of shape (num_sequences, seq_length). These are the input sequences.
2. target: A 1D array of shape (num_sequences). These are the next values corresponding to each sequence.
"""

#Example of the 2 arrays

data = [
    [0.0, 0.5, 1.0],
    [0.5, 1.0, 0.5],
    [1.0, 0.5, 0.0],
    [0.5, 0.0, -0.5]
]
target = [0.5, 0.0, -0.5, -1.0]

"""A **stacked layer** in the context of LSTMs (or any neural network) refers to having multiple LSTM layers stacked on top of each other. Each layer processes the sequential data and passes its output as input to the next layer. This stacking allows the model to learn hierarchical patterns and more complex temporal dependencies.

### Key Concept of Stacked Layers

1. Single Layer LSTM:
    * In a single-layer LSTM, the input sequence is passed through one LSTM layer, and the hidden states are directly used for the output.
    * Example:
      * Input → LSTM Layer → Output

2. Stacked LSTM:
    * In a stacked LSTM, the output of one LSTM layer becomes the input to the next LSTM layer.
    * This creates a deeper architecture, enabling the model to capture higher-level features of the data.
    * Example:
      * Input → LSTM Layer 1 → LSTM Layer 2 → Output
"""