{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "K-fold cross-validation is a widely used statistical method for **assessing the performance** of a machine learning model.\n",
        "It involves dividing a dataset into K equally-sized subsets or \"folds\" and then systematically training and testing the model on these folds to evaluate its performance."
      ],
      "metadata": {
        "id": "Fyasg-UfhQjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in K-Fold Cross-Validation\n",
        "\n",
        "\n",
        "1.   Split the Data:\n",
        "        * The dataset is randomly shuffled and then divided into K subsets (folds) of roughly equal size.\n",
        "        * For example, if K=5, the data is split into five folds.\n",
        "\n",
        "2.   Iterate through Folds:\n",
        "        * For each iteration, 1 fold is used as the test set, and the remaining K−1 folds are combined to form the training set.\n",
        "        * This process is repeated K times so that each fold serves as the test set exactly once.\n",
        "\n",
        "3.   Train and Test:\n",
        "        * The model is trained on the training set and evaluated on the test set in each iteration.\n",
        "        * Performance metrics (e.g., accuracy, precision, recall, RMSE) are recorded for each fold.\n",
        "\n",
        "4.   Aggregate Results:\n",
        "        * K iterations, the performance metrics are averaged to produce a single overall estimate of the model's performance."
      ],
      "metadata": {
        "id": "Tv77kbsxhiNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example\n",
        "\n",
        "1. Fold 1: Samples 1–20 are the test set; samples 21–100 are the training set.\n",
        "2. Fold 2: Samples 21–40 are the test set; samples 1–20 and 41–100 are the training set.\n",
        ".\n",
        ".\n",
        "5. Fold 5: Samples 81–100 are the test set; samples 1–80 are the training set.\n",
        "\n",
        "The final performance metric is the average of the metrics obtained in each fold."
      ],
      "metadata": {
        "id": "zTPOPDMEiRgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages\n",
        "\n",
        "1. **Robust Evaluation**: Reduces the risk of overfitting to a specific test set by using multiple test sets.\n",
        "\n",
        "2. **Efficient Use of Data**: Utilizes the entire dataset for both training and testing.\n",
        "\n",
        "3. **Fair Comparison**: Especially useful for comparing models since it gives a consistent way to evaluate them."
      ],
      "metadata": {
        "id": "qJWWbHRmigcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variations\n",
        "\n",
        "1. **Stratified K-Fold**: Ensures that the folds have approximately the same distribution of class labels (used for classification problems with imbalanced data).\n",
        "\n",
        "2. **Leave-One-Out (LOO)**: A special case where K=N, and each data point is used as a test set once. This is computationally expensive.\n",
        "\n",
        "3. **Repeated K-Fold**: Repeats K-fold cross-validation multiple times with different splits to further reduce variability in the performance estimate.\n",
        "\n",
        "K-fold is a powerful and versatile method for model evaluation and helps in ensuring that a model generalizes well to unseen data."
      ],
      "metadata": {
        "id": "YwrwekQkizBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s an example of implementing K-fold cross-validation using scikit-learn in Python:"
      ],
      "metadata": {
        "id": "BbZFz1XfjH4-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PqTbUWu3Kq8C"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target"
      ],
      "metadata": {
        "id": "sPgGluikjLGe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize K-Fold cross-validator\n",
        "k = 5  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "KoKKxbxCjNjQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = RandomForestClassifier(random_state=42)"
      ],
      "metadata": {
        "id": "J9kvJFPqjR0v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store results\n",
        "fold_accuracies = []\n",
        "\n",
        "# Perform K-Fold Cross-Validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split data\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    fold_accuracies.append(accuracy)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracies for each fold: {fold_accuracies}\")\n",
        "print(f\"Average accuracy: {np.mean(fold_accuracies):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8GTyfkFjVvh",
        "outputId": "39b821b7-b722-4174-df65-ab678f453fe9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracies for each fold: [1.0, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667]\n",
            "Average accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation\n",
        "\n",
        "1. Dataset:\n",
        "    * We use the Iris dataset, a popular dataset for classification.\n",
        "\n",
        "2. K-Fold:\n",
        "    * We create a KFold object with K=5, enabling shuffling for random splits.\n",
        "\n",
        "3. Training and Testing:\n",
        "    * In each fold, the indices for training and testing are determined by kf.split(X).\n",
        "    * The model is trained on the training set and tested on the test set.\n",
        "\n",
        "4. Evaluation:\n",
        "    * Accuracy is calculated for each fold using accuracy_score.\n",
        "\n",
        "5. Results:\n",
        "    * The fold accuracies and the average accuracy are printed."
      ],
      "metadata": {
        "id": "secy5nnAjcu0"
      }
    }
  ]
}