Parameter,Value
Trial,1
optimizer,adam
dropout_rate,0.2
units_per_layer,[50]
batch_size,16
epochs,20
activation,relu
loss,0.2503349483013153

Trial,2
optimizer,adam
dropout_rate,0.2
units_per_layer,[50]
batch_size,16
epochs,20
activation,sigmoid
loss,0.17162543535232544

Trial,3
optimizer,adam
dropout_rate,0.2
units_per_layer,[50]
batch_size,32
epochs,20
activation,relu
loss,0.20467814803123474

Trial,4
optimizer,adam
dropout_rate,0.2
units_per_layer,[50]
batch_size,32
epochs,20
activation,sigmoid
loss,0.16224858164787292

Trial,5
optimizer,adam
dropout_rate,0.2
units_per_layer,"[50, 100]"
batch_size,16
epochs,20
activation,relu
loss,0.2802334725856781

Trial,6
optimizer,adam
dropout_rate,0.2
units_per_layer,"[50, 100]"
batch_size,16
epochs,20
activation,sigmoid
loss,0.1711256206035614

Trial,7
optimizer,adam
dropout_rate,0.2
units_per_layer,"[50, 100]"
batch_size,32
epochs,20
activation,relu
loss,0.4109814763069153

Trial,8
optimizer,adam
dropout_rate,0.2
units_per_layer,"[50, 100]"
batch_size,32
epochs,20
activation,sigmoid
loss,0.12834453582763672

Trial,9
optimizer,adam
dropout_rate,0.3
units_per_layer,[50]
batch_size,16
epochs,20
activation,relu
loss,0.21710771322250366

Trial,10
optimizer,adam
dropout_rate,0.3
units_per_layer,[50]
batch_size,16
epochs,20
activation,sigmoid
loss,0.1993284374475479

Trial,11
optimizer,adam
dropout_rate,0.3
units_per_layer,[50]
batch_size,32
epochs,20
activation,relu
loss,0.1566016972064972

Trial,12
optimizer,adam
dropout_rate,0.3
units_per_layer,[50]
batch_size,32
epochs,20
activation,sigmoid
loss,0.14668479561805725

Trial,13
optimizer,adam
dropout_rate,0.3
units_per_layer,"[50, 100]"
batch_size,16
epochs,20
activation,relu
loss,0.29335638880729675

Trial,14
optimizer,adam
dropout_rate,0.3
units_per_layer,"[50, 100]"
batch_size,16
epochs,20
activation,sigmoid
loss,0.22728271782398224

Trial,15
optimizer,adam
dropout_rate,0.3
units_per_layer,"[50, 100]"
batch_size,32
epochs,20
activation,relu
loss,0.23138859868049622

Trial,16
optimizer,adam
dropout_rate,0.3
units_per_layer,"[50, 100]"
batch_size,32
epochs,20
activation,sigmoid
loss,0.18491730093955994

Trial,17
optimizer,rmsprop
dropout_rate,0.2
units_per_layer,[50]
batch_size,16
epochs,20
activation,relu
loss,0.21877416968345642

Trial,18
optimizer,rmsprop
dropout_rate,0.2
units_per_layer,[50]
batch_size,16
epochs,20
activation,sigmoid
loss,0.16975165903568268

Trial,19
optimizer,rmsprop
dropout_rate,0.2
units_per_layer,[50]
batch_size,32
epochs,20
activation,relu
loss,0.2046012133359909

Trial,20
optimizer,rmsprop
dropout_rate,0.2
units_per_layer,[50]
batch_size,32
epochs,20
activation,sigmoid
loss,0.15687201917171478

Trial,21
optimizer,rmsprop
dropout_rate,0.2
units_per_layer,"[50, 100]"
batch_size,16
epochs,20
activation,relu
loss,0.2110973745584488

Trial,22
optimizer,rmsprop
dropout_rate,0.2
units_per_layer,"[50, 100]"
batch_size,16
epochs,20
activation,sigmoid
loss,0.1275743842124939

Trial,23
optimizer,rmsprop
dropout_rate,0.2
units_per_layer,"[50, 100]"
batch_size,32
epochs,20
activation,relu
loss,0.21732939779758453

Trial,24
optimizer,rmsprop
dropout_rate,0.2
units_per_layer,"[50, 100]"
batch_size,32
epochs,20
activation,sigmoid
loss,0.12497647106647491

Trial,25
optimizer,rmsprop
dropout_rate,0.3
units_per_layer,[50]
batch_size,16
epochs,20
activation,relu
loss,0.22057244181632996

Trial,26
optimizer,rmsprop
dropout_rate,0.3
units_per_layer,[50]
batch_size,16
epochs,20
activation,sigmoid
loss,0.16852977871894836

Trial,27
optimizer,rmsprop
dropout_rate,0.3
units_per_layer,[50]
batch_size,32
epochs,20
activation,relu
loss,0.20252515375614166

Trial,28
optimizer,rmsprop
dropout_rate,0.3
units_per_layer,[50]
batch_size,32
epochs,20
activation,sigmoid
loss,0.13995309174060822

Trial,29
optimizer,rmsprop
dropout_rate,0.3
units_per_layer,"[50, 100]"
batch_size,16
epochs,20
activation,relu
loss,0.2225644886493683

Trial,30
optimizer,rmsprop
dropout_rate,0.3
units_per_layer,"[50, 100]"
batch_size,16
epochs,20
activation,sigmoid
loss,0.1724671870470047

Trial,31
optimizer,rmsprop
dropout_rate,0.3
units_per_layer,"[50, 100]"
batch_size,32
epochs,20
activation,relu
loss,0.23604470491409302

Trial,32
optimizer,rmsprop
dropout_rate,0.3
units_per_layer,"[50, 100]"
batch_size,32
epochs,20
activation,sigmoid
loss,0.22273282706737518

