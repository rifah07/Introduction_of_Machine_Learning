{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##A Graph Neural Network (GNN) is a type of neural network designed to work with graph-structured data.\n",
        "In graphs:\n",
        "* Nodes represent entities.\n",
        "* Edges represent relationships between entities.\n",
        "* Features can be associated with nodes (node features) or edges (edge features).\n",
        "\n",
        "GNNs process these graphs by learning to represent nodes, edges, or the entire graph in a way that captures the graph structure and feature information. They are widely used in applications like social networks, molecular chemistry, and recommendation systems."
      ],
      "metadata": {
        "id": "3_oeOYABzqUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Key Concepts of GNNs\n",
        "\n",
        "* Graph Representation: A graph is represented by:\n",
        "    * An adjacency matrix that defines connections between nodes\n",
        "    * A feature matrix that represents node-specific data\n",
        "\n",
        "* Message Passing: GNNs operate by exchanging information (\"messages\") between neighboring nodes in the graph. Nodes aggregate information from their neighbors to update their own features.\n",
        "\n",
        "* Layers: Each layer of a GNN updates the node features based on:\n",
        "\n",
        "    * The node's current features.\n",
        "    * The aggregated features of its neighbors.\n",
        "\n",
        "* Output:\n",
        "    * Node-level outputs (e.g., classification of individual nodes).\n",
        "    * Edge-level outputs (e.g., predicting relationships between nodes).\n",
        "    * Graph-level outputs (e.g., predicting a property of the entire graph)."
      ],
      "metadata": {
        "id": "DAd1LRO7z1Ku"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KPaH90Rfyry_"
      },
      "outputs": [],
      "source": [
        "#!pip install torch torchvision torchaudio torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.datasets import Planetoid"
      ],
      "metadata": {
        "id": "cLzNVfzmy5bW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Cora dataset (common benchmark dataset for GNNs)\n",
        "dataset = Planetoid(root=\"/tmp/Cora\", name=\"Cora\")"
      ],
      "metadata": {
        "id": "EN_EnHg4y8Pi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset:\n",
        "\n",
        "In this example, we use the Cora dataset:\n",
        "\n",
        "  1. Nodes represent research papers.\n",
        "  2. Edges represent citation relationships.\n",
        "  3. Node features are word vectors from the paper abstracts.\n",
        "  4. Labels represent the research field of each paper."
      ],
      "metadata": {
        "id": "dN9ZvHj-0eP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        # First Graph Convolution + ReLU\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        # Second Graph Convolution + Softmax\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "Qom-dkh1y_G4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GCNConv**: A Graph Convolutional Layer (from PyTorch Geometric). It implements message passing to update node features using neighbors' features.\n",
        "    * in_channels: Number of features for each node.\n",
        "    * hidden_channels: Intermediate representation size.\n",
        "    * out_channels: Number of classes for classification."
      ],
      "metadata": {
        "id": "F0iwXIdo000E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* data.x: Node features (input to the model).\n",
        "* data.edge_index: Connectivity of the graph.\n",
        "* Message Passing:\n",
        "     * In self.conv1, node features are updated by aggregating features from neighbors.\n",
        "     * In self.conv2, the aggregated features are transformed again to predict class probabilities."
      ],
      "metadata": {
        "id": "gCzf8wey1C0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset and model\n",
        "data = dataset[0]  # Cora has only one graph\n",
        "model = GNN(in_channels=dataset.num_node_features, hidden_channels=16, out_channels=dataset.num_classes)"
      ],
      "metadata": {
        "id": "jmR6OlQ7zBKF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.NLLLoss()"
      ],
      "metadata": {
        "id": "EH5ZTpmzzEos"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "bhfYZIvozKo8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Loss Function: NLLLoss is used because the output is log probabilities (log_softmax).\n",
        "* Train Mask: Specifies which nodes to use for training."
      ],
      "metadata": {
        "id": "U6U4y1gH1Vna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function\n",
        "def test():\n",
        "    model.eval()\n",
        "    out = model(data)\n",
        "    pred = out.argmax(dim=1)  # Get predictions\n",
        "    correct = pred[data.test_mask] == data.y[data.test_mask]  # Compare with true labels\n",
        "    acc = int(correct.sum()) / int(data.test_mask.sum())\n",
        "    return acc"
      ],
      "metadata": {
        "id": "fE0-SNXMzMur"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "for epoch in range(200):\n",
        "    loss = train()\n",
        "    acc = test()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lwzDWoGzOt6",
        "outputId": "84f763ac-a220-47a8-e72b-dbe1b3ac1293"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.9455, Test Accuracy: 0.5200\n",
            "Epoch 10, Loss: 0.6057, Test Accuracy: 0.8040\n",
            "Epoch 20, Loss: 0.1160, Test Accuracy: 0.7950\n",
            "Epoch 30, Loss: 0.0300, Test Accuracy: 0.7920\n",
            "Epoch 40, Loss: 0.0156, Test Accuracy: 0.7950\n",
            "Epoch 50, Loss: 0.0136, Test Accuracy: 0.8020\n",
            "Epoch 60, Loss: 0.0148, Test Accuracy: 0.8090\n",
            "Epoch 70, Loss: 0.0164, Test Accuracy: 0.8070\n",
            "Epoch 80, Loss: 0.0171, Test Accuracy: 0.8090\n",
            "Epoch 90, Loss: 0.0167, Test Accuracy: 0.8090\n",
            "Epoch 100, Loss: 0.0158, Test Accuracy: 0.8120\n",
            "Epoch 110, Loss: 0.0149, Test Accuracy: 0.8130\n",
            "Epoch 120, Loss: 0.0141, Test Accuracy: 0.8120\n",
            "Epoch 130, Loss: 0.0134, Test Accuracy: 0.8060\n",
            "Epoch 140, Loss: 0.0128, Test Accuracy: 0.8040\n",
            "Epoch 150, Loss: 0.0123, Test Accuracy: 0.8050\n",
            "Epoch 160, Loss: 0.0118, Test Accuracy: 0.8050\n",
            "Epoch 170, Loss: 0.0114, Test Accuracy: 0.8060\n",
            "Epoch 180, Loss: 0.0110, Test Accuracy: 0.8050\n",
            "Epoch 190, Loss: 0.0107, Test Accuracy: 0.8060\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How is the GNN Implemented?\n",
        "  1. Graph Representation: The input graph is represented using:\n",
        "      * data.x: Feature matrix.\n",
        "      * data.edge_index: Connectivity matrix (edges).\n",
        "  2. Message Passing: Implemented through GCNConv layers. Each layer aggregates information from neighbors to update node features.\n",
        "  3. Node Classification: The model learns to classify nodes into categories by training on labeled nodes (train_mask) and testing on a separate set of nodes (test_mask).\n",
        "  4. Training Pipeline:\n",
        "      * Forward pass through the GNN.\n",
        "      * Compute the loss for labeled nodes.\n",
        "      * Backpropagate to update parameters."
      ],
      "metadata": {
        "id": "XXktesqT2hL5"
      }
    }
  ]
}